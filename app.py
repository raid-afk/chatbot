import streamlit as st
from groq import Groq
import PyPDF2

# --- 1. CONFIGURATION PAGE ---
st.set_page_config(
    page_title="Assistant AI Pro",
    page_icon="üìÑ",
    layout="wide"
)

# --- 2. STYLE CSS (Clean & Minimaliste) ---
st.markdown("""
<style>
    /* Fond blanc et texte sombre */
    .stApp {
        background-color: #FFFFFF;
        color: #111827;
    }
    
    /* Sidebar discr√®te */
    section[data-testid="stSidebar"] {
        background-color: #F9FAFB;
        border-right: 1px solid #E5E7EB;
    }
    
    /* Inputs propres */
    .stTextInput input, .stSelectbox div[data-baseweb="select"], .stChatInput textarea {
        background-color: #FFFFFF !important;
        border: 1px solid #D1D5DB !important;
        border-radius: 8px !important;
        color: #111827 !important;
    }
    
    /* Boutons bleus */
    .stButton button {
        background-color: #2563EB !important;
        color: white !important;
        border-radius: 6px !important;
        border: none !important;
    }
    
    /* Cacher menu hamburger */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# --- 3. FONCTIONS ---

# Lecture PDF
def extract_text_from_pdf(pdf_file):
    try:
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() or ""
        return text
    except Exception as e:
        return ""

# G√©n√©rateur pour nettoyer le flux (Fixe le probl√®me d'affichage JSON)
def generate_chat_responses(chat_completion):
    """Extrait uniquement le texte du flux de r√©ponse."""
    for chunk in chat_completion:
        if chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content

# --- 4. INTERFACE ---
st.title("Assistant Documentaire")
st.caption("Interface simplifi√©e v2.1 ‚Ä¢ Lecture PDF active")
st.markdown("---")

# BARRE LAT√âRALE
with st.sidebar:
    st.header("R√©glages")
    
    # Cl√© API
    api_key = st.secrets.get("GROQ_API_KEY")
    if not api_key:
        api_key = st.text_input("Cl√© API Groq", type="password", placeholder="gsk_...")
    else:
        st.success("‚úÖ Syst√®me Connect√©")

    st.markdown("### Mod√®le IA")
    
    # CORRECTION CRITIQUE 1 : Dictionnaire de mapping
    # √Ä gauche : Ce qu'on voit. √Ä droite : L'ID technique pour l'API.
    models_map = {
        "Mode Puissant ": "llama-3.3-70b-versatile",
        "Mode Rapide ": "llama3-8b-8192",
        "Mode √âquilibr√© ": "mixtral-8x7b-32768"
    }
    
    # On laisse l'utilisateur choisir la "Cl√©" (le texte lisible)
    selected_label = st.selectbox("Moteur", list(models_map.keys()), label_visibility="collapsed")
    # On r√©cup√®re la "Valeur" (l'ID technique) gr√¢ce √† la cl√©
    selected_model_id = models_map[selected_label]

    st.markdown("### Document")
    uploaded_file = st.file_uploader("Charger un PDF", type="pdf")
    
    st.markdown("---")
    if st.button("Nouvelle conversation", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# --- 5. LOGIQUE CHAT ---
if api_key:
    client = Groq(api_key=api_key)

    if "messages" not in st.session_state:
        st.session_state.messages = []
        st.session_state.messages.append({"role": "assistant", "content": "Bonjour. Je suis pr√™t √† analyser vos documents."})

    # Gestion Contexte
    pdf_context = ""
    if uploaded_file:
        raw_text = extract_text_from_pdf(uploaded_file)
        if raw_text:
            pdf_context = f"CONTEXTE PDF : {raw_text[:30000]} \n\n"
            st.toast("Document analys√© avec succ√®s.", icon="üìé")

    # Afficher historique
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Input Utilisateur
    if prompt := st.chat_input("Votre question..."):
        
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Pr√©paration Prompt
        messages_api = []
        system_instruction = "Tu es un assistant professionnel. R√©ponds en fran√ßais de mani√®re claire et structur√©e."
        
        if pdf_context:
            system_instruction += " Utilise les informations du PDF fourni pour r√©pondre."
            messages_api.append({"role": "system", "content": pdf_context})
        
        messages_api.append({"role": "system", "content": system_instruction})
        
        for m in st.session_state.messages:
            if m["role"] != "system":
                messages_api.append(m)

        # G√©n√©ration R√©ponse
        with st.chat_message("assistant"):
            try:
                stream = client.chat.completions.create(
                    messages=messages_api,
                    model=selected_model_id, # Utilisation de l'ID correct
                    stream=True,
                    temperature=0.5
                )
                # CORRECTION CRITIQUE 2 : On passe par le g√©n√©rateur de nettoyage
                response = st.write_stream(generate_chat_responses(stream))
                
                # Sauvegarde en session
                st.session_state.messages.append({"role": "assistant", "content": response})
                
            except Exception as e:
                st.error(f"Erreur API : {e}")

else:
    st.info("Veuillez entrer une cl√© API valide dans la barre lat√©rale.")